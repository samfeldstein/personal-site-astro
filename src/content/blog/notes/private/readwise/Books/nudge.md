---
title: "Nudge"
author: Richard H. Thaler and Cass R. Sunstein
---

> Small and apparently insignificant details can have major impacts on people’s behavior. A good rule of thumb is to assume that everything matters.


> If, all things considered, you think that Carolyn should take the opportunity to nudge the kids toward food that is better for them, Option 1, then we welcome you to our movement: libertarian paternalism.


> When we use the term libertarian to modify the word paternalism, we simply mean liberty-preserving.


> The paternalistic aspect lies in the claim that it is legitimate for choice architects to try to influence people’s behavior in order to make their lives longer, healthier, and better. In other words, we argue for self-conscious efforts, by institutions in the private sector and by government, to steer people’s choices in directions that will improve their lives.


> many people seem at least implicitly committed to the idea of Homo economicus, or economic man—the notion that each of us thinks and chooses unfailingly well, and thus fits within the usual depiction of human beings that is offered by economists.


> Unlike Econs, Humans make predictable mistakes. Take, for example, the planning fallacy—the systematic tendency toward unrealistic optimism about the time it takes to complete projects. It will come as no surprise to anyone who has ever hired a contractor to learn that everything takes longer than you think, even if you know about the planning fallacy.*


> Research shows that whatever the default choices are, many people stick with them, even when the stakes are much higher than choosing the sound your phone makes when it rings.


> The false assumption is that almost all people, almost all the time, make choices that are in their best interest or at the very least are better than the choices that would be made by someone else. We claim that this assumption is false—indeed, obviously false. In fact, we do not think that anyone actually believes it on reflection.


> The first misconception is that it is possible to avoid influencing people’s choices. In countless situations, some organization or agent must make a choice that will affect the behavior of some other people.


> In the United Kingdom, former Prime Minister David Cameron, the leader of the Conservative Party, embraced nudging and created the world’s first team devoted solely to this effort, officially called the Behavioural Insights Team, but often called the Nudge Unit.*

Job opp?


> we want to stress that we are not saying that people are irrational. We avoid using that unhelpful and unkind term, and we certainly don’t think that people are dumb. Rather, the problem is that we are fallible and life is hard. If every time we went food shopping, we tried to solve the problem of choosing the very best possible combination of items to buy, we would never get out of the store. Instead, we take sensible shortcuts, and we try to get home before we start eating the things in our cart. We are human.


> Tom Parker’s fascinating 1983 book, Rules of Thumb.


> This process is called “anchoring and adjustment.” You start with some anchor, a number you know, and adjust in the direction you think is appropriate.


> On balance, the screen with the relatively higher default tips significantly increased drivers’ earnings, because they increased the average tip. But interestingly, they also provoked an increase in the number of riders who offered no tip at all. Some people were evidently put off by the aggressive defaults, and they refused to give anything.3 This is connected with the behavioral phenomenon of reactance: when people feel ordered around, they might get mad and do the opposite of what is being ordered (or even suggested).


> the evidence shows that, within reason, the more you ask for, the more you tend to get.


> In the United States, are more gun deaths caused by homicides or suicides? In answering questions of this kind, most people use what is called the availability heuristic. They assess the likelihood of risks by asking how readily examples come to mind. Because homicides are much more heavily reported in the news media, they are more available than suicides, and so people tend to believe, wrongly, that guns cause more deaths from homicide than from suicide.


> Such misperceptions can affect policy, because some governments will allocate their resources in a way that fits with people’s fears rather than in response to the most likely dangers.


> The third of the original three heuristics bears an unwieldy name: representativeness. Think of it as the similarity heuristic. The idea is that when asked to judge how likely it is that A belongs to category B, people answer by asking themselves how similar A is to their image or stereotype of B (that is, how “representative” A is of B). Like the other two heuristics we have discussed, this one is used because it often works. Stereotypes are sometimes right!


> Unrealistic optimism is a pervasive feature of human life; it characterizes most people in most social categories.


> People hate losses. In more technical language, people are “loss averse.” Roughly speaking, the prospect of losing something makes you twice as miserable as the prospect of gaining the same thing makes you happy. How do we know this?


> Loss aversion has a lot of relevance to public policy. If you want to discourage the use of plastic bags, should you give people a small amount of money for bringing their own reusable bag, or should you ask them to pay the same small amount for a plastic bag? The evidence suggests that the former approach has no effect at all, but that the latter works; it significantly decreases use of plastic bags. People don’t want to lose money, even if the amount is trivial.13 (Environmentalists, please remember this point.)


> For lots of reasons, people have a general tendency to stick with their current situation. One reason is loss aversion; giving up what we have is painful. But the phenomenon has multiple causes. William Samuelson and Richard Zeckhauser have dubbed this behavior status quo bias, and it has been demonstrated in numerous situations.


> The combination of loss aversion and mindless choosing is one reason why if an option is designated as the default, it will usually (but not always!) attract a large market share.


> The credit card companies had a good, intuitive understanding of what psychologists would come to call framing. The idea is that choices depend, in part, on the way in which problems are described.


> It is useful to imagine the workings of the brain as consisting of two components or systems. One is fast and intuitive; the other is slow and reflective. Kahneman adopts the terminology of the psychology literature on which he draws, and calls these two components System 1 and System 2. One of us had trouble remembering which one is the fast one (it is 1), so we prefer to use names that remind the reader what they are. We call them the Automatic System and the Reflective System.


> In the language of economics, the group is said to display behavior that is dynamically inconsistent. Initially people prefer Option A to Option B, but they later choose B over A. We can see dynamic inconsistency in many places. On Saturday morning, people might say that they prefer to go for a run later in the day, but once the afternoon comes, they are on the couch at home watching the football game or binge-watching the entire season of a new show.


> Thaler removing the cashews and Ulysses tying himself to the mast are examples of commitment strategies. (A reminder: Calling this the Final Edition of this book is a commitment strategy. Really.) Such strategies work well if the risk of submitting to temptation can be anticipated, and removing the temptation is feasible.


> in many situations we do not correctly forecast a pending self-control problem because we underestimate the effect of arousal. This is something the behavioral economist George Loewenstein calls the “hot-cold empathy gap,” a concept that has heavily influenced our thinking on this subject. Loewenstein’s key insight is that even if people realize that they behave differently when aroused, they underestimate the strength of the effect.


> Loewenstein’s key insight is that even if people realize that they behave differently when aroused, they underestimate the strength of the effect. When in a cold state, we do not appreciate the extent to which our desires and our behavior will be altered when we are “under the influence” of arousal. As a result, our behavior reflects a certain naivete about the effects that context can have on choice.


> people are far more likely to splurge impulsively on a big luxury purchase when they receive an unexpected windfall than they are with savings that they have accumulated over time, even if those savings are fully available to be spent.


> the confidence heuristic: people tend to think that confident speakers must be correct. The clear lesson here is that consistent and unwavering people, in the private or public sector, can move groups and practices in their preferred direction. An important implication is that if senior members of a group want to obtain the actual beliefs of their junior coworkers, they will ask for those beliefs independently (so coworkers don’t influence each other) and, most important, before they state their own opinion.


> In all eight worlds, individuals were far more likely to download songs that had been previously downloaded in significant numbers, and far less likely to download songs that had not been as popular. For that reason, initial popularity greatly mattered; it could make all the difference between success and failure.


> For choice architects who want to use social influences, a challenge is to work with, rather than against, people’s sense of who they are. That sense might have to do with nationality, culture, region, ethnicity, religion, politics, or a favorite team. We might even give it a name: identity-based cognition.


> Explicitly targeting the unresponsive audience, the state enlisted popular Dallas Cowboys football players to participate in television ads in which they collected litter, smashed beer cans in their bare hands, and growled, “Don’t mess with Texas!” Other spots included popular singers, such as Willie Nelson.


> pluralistic ignorance—that is, ignorance, on the part of all or most, about what other people think.


> If people wrongly think that most people are committed to a long-standing social norm, a small nudge correcting that misperception can inaugurate large-scale change.


> A voluminous body of research finds that informing people about the social norm can be extremely effective.


> (Note to political parties: If you would like to increase turnout, please do not lament the large numbers of people who fail to vote. But do tell people that many of their neighbors vote!)


> Call it the golden rule of libertarian paternalism: offer nudges that are most likely to help and least likely to inflict harm.*


> Lower-status members of the team, such as nurses, might normally be reluctant to pipe up if a famous surgeon has skipped a step, but if it is considered part of their job, they do it. By the way, this is a completely general principle. All organizations work better if everyone is empowered to speak up when the boss is about to make a mistake.


> Self-control issues are most likely to arise when choices and their consequences are separated in time.


> Unfortunately, some of life’s most important decisions do not come with many opportunities to practice. Most students choose a college only once. Outside of Hollywood, most of us choose a spouse, well, not more than two or three times. Few of us get to try many different careers. And outside of science fiction, we get one chance to save for retirement (though we can make some adjustments along the way). Generally, the higher the stakes, the less often we are able to practice.


> Learning is most likely if people get immediate, clear feedback after each try.


> Alas, many of life’s choices are like practicing putting without being able to see where the balls end up, and for one simple reason: the situation is not structured to provide good feedback. For example, we usually get feedback only on the options we select, not the ones we reject. Unless people go out of their way to experiment, they may never learn about alternatives to the familiar ones. If you take the longer route home every night, you may never learn there is a shorter one. Long-term processes rarely provide good feedback. Someone can eat a high-fat diet for years without having any strong warning signs until they have a heart attack. When feedback is ineffective, we may benefit from a nudge.


> When people have a hard time predicting how their choices will end up affecting their lives, they have less to gain from having numerous options and perhaps even from choosing for themselves. A nudge might be welcomed.


> The discussion thus far suggests that people may most need a good nudge for choices that require memory or have delayed effects; those that are difficult, are infrequent, and offer poor feedback; and those for which the relationship between choice and experience is ambiguous.


> Much of the time, more money can made by catering to human frailties than by helping people to avoid them.


> Those doors are bad architecture because they violate a simple psychological principle with a fancy name: stimulus response compatibility. The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.


> A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off.


> Good choice architects often winnow the choice set down to a manageable size.


> If the price of a product goes up, suppliers will usually produce more of it and consumers will usually want less of it.


> One way to start to think about incentives is to ask four questions about a particular choice architecture: Who chooses? Who uses? Who pays? Who profits?


> When the answers to the first three questions above is one person, markets tend to work reasonably well, at least so long as people have adequate information and are not suffering from behavioral biases.


> What do successful bookstores (and other small retail establishments) have in common? They are good curators.


> Fun is the final element of good choice architecture that we discuss. As you know, the first mantra of nudging is to make it easy to take the desired action. A good complement to this advice is to make the desired activity fun.


> Whenever we can make some activity seem like play, pique our curiosity, or build excitement or anticipation, we will find that people are not only willing to undertake that activity; they even may be willing to pay for the opportunity!


> When lotteries are used to motivate people, it is important to get the details right. Participants are likely to find a lottery more enticing if they find out whether they would have won. The Dutch government uses this principle very effectively. One of its state lotteries is based on postal codes. If your postal code is announced as the winner, you know that you would have won had you only bought a ticket. The idea is to play on people’s feelings of regret.


> we can improve decision making in these and other domains, and in so doing, make the market for goods and services much more transparent, competitive, and fair. We can do all that by improving one aspect of the choice architecture: how information is collected and made available to consumers. We call this Smart Disclosure.


> Let’s return to the plight of the parents of the child with a nut allergy. Suppose they do most of their shopping at a large supermarket in their neighborhood. If it is part of a chain, there is a good chance this supermarket has some kind of “shopper’s club” that keeps track of what each household buys. We think that parents—and all other customers—should have the right to access that shopping history, including from online shopping services. Why might they want that data? Well, suppose that with just a couple of clicks, they could download all their purchases over the past six months in a format that allows them to be uploaded to a website that offered to search through all their purchases and find the ones that they might want to take off their future shopping lists (on the basis of specified criteria, such as nuts, high calories, lots of sugar, or high prices). The website might even recommend good substitutes.

Website idea. #website-ideas


> Perhaps the most basic principle of good choice architecture is our mantra: Make It Easy. If you want to encourage some behavior, figure out why people aren’t doing it already, and eliminate the barriers that are standing in their way.


> this principle has an obvious corollary: if you want to discourage some behavior, make it harder by creating barriers.


> We use the term to mean this: any aspect of choice architecture consisting of friction that makes it harder for people to obtain an outcome that will make them better off (by their own lights).


> there is essentially no evidence that past performance predicts future performance.


> Just as you should regularly reboot your computer, we think it is healthy for investors to be encouraged occasionally (once every twenty years does not seem too often) just to start over.


> It seems a good bet that nudges will have the longest life when people are on autopilot, in which case default rules are likely to be sticky. In outer space, an object that has been nudged will keep going in that direction until it is nudged again.


> In a series of experiments, the behavioral economists Ernst Fehr and Simon Gächter have shown that cooperation in repeated public goods games can be increased if players are allowed to punish noncooperators at their own expense.




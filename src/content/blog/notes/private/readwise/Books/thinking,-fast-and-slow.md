---
title: "Thinking, Fast and Slow"
author: Daniel Kahneman
---

> System 2 is activated when an event is detected that violates the model of the world System 1 maintains.


> Constantly questioning our own thinking would be impossibly tedious, and System 2 is much too slow and inefficient to serve as a substitute for System 1 in making routine decisions. The best we can do is a compromise: learn to recognize situations in which mistakes are likely and try harder to avoid significant mistakes when the mistakes are high.


> As you become skilled in a task, it's demand for energy diminishes.


> Self-control and deliberate thought apparently draw on the same limited budget of effort.


> Riding a motorcycle at 150 miles an hour and playing a competitive game of chess are certainly very effortful. In a state of flow however, maintaining focused attention on these absorbing activities requires no exertion of self-control, thereby freeing resources to be directed to the task at hand.

Can you race a motorcyle at 150 miles an hour and *not* be in a state of flow? If your attention falters, you die.


> The most surprising discovery made by Baumeister's group shows that the idea of mental energy is more than a metaphor. The nervous system consumes more glucose than most other parts of the body, and effortful mental activity appears to be especially expensive in the currency of glucose. When you are actively involved in cognitive reasoning or engaged in a task that requires self-control, your blood glucose level drops.
>  The bold implication of this idea is that the effects of ego depletion could be undone by ingesting glucose, and Baumeister and his colleagues have confirmed this in several experiments.


> The evidence of studies of priming suggests that reminding people of their mortality increases the appeal of authoritarian ideas, which may become reassuring in the context of the terror of death.


> Words that you have seen before become easier to see again--you can identify them better than other words when they are shown very briefly or masked by noise, and you will be quicker (by a few hundreds of a second) to read them than to read other words. In short, you experience greater cognitive ease in perceiving a word you have seen earlier, and it is this sense of of ease that gives you the impression of familiarity.


> If you want to write a persuasive message, the general principal is that anything you can do to reduce cognitive strain will help, so you should first maximize eligibility.


> How do you know that a statement is true? If it is strongly linked by logic or association to other beliefs or preferences you hold, or comes from a source you trust and like, you will feel a sense of cognitive ease. The trouble is that there may be other causes for your feeling of ease, including the quality of the font and the appealing rhythm of the prose, and you have no simple way of tracing your feelings to their source


> The experience of cognitive strain, whatever its source, tends to mobilize System 2, shifting people's approach to problems from a casual intuitive mode to a more engaged and analytic mode.

He cites an example where students were asked to take a test. For some, the text was legible. For others, it was barely legible. The students who took the barely legible test made fewer mistakes.


> When we are uncomfortable and unhappy, we lose touch with our intution.

And don't we get better at problem-solving under those circumstances? So is there an inverse relationship between the effectiveness of System 1 and 2? And the dial is our mood and cognitive comfort?


> When System 2 is otherwise engaged, we will believe almost anything. System 1 is gullible and biased to believe. System 2 is in charge of doubting and unbelieving, but System 2 is sometimes busy, and often lazy.


> The measure of success for System 1 is the coherence of the story it manages to create. The amount and quality of the data on which the story is based are largely irrelevant.


> Those who speak early and assertively cause others to line up behind them.


> Ratings of competence were far more predictive of voting outcomes in Todorov's study than ratings of likability.


> System 1 deals well with averages but poorly with sums.

In other words, System 1 can see the forest but not the trees.


> The number of birds made very little difference. What the participants reacted to in all three groups was a prototype--the awful image of a helpless bird drowning, its feather soaked in thick oil.


> I propose a simple account of how we generate intuitive opinions on complex matters. If a satisfactory answer to a hard question is not found quickly, System 1 will find a related question that is easier and will answer it. I call the operation of answering one question in place of another *substitution*.


> When people consider a particular value for an unknown quantity before estimating that quantity, their estimates stay close to the number that they first considered. This is called the anchoring effect.



